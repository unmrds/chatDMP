{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78209c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import getpass\n",
    "import random\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37216778",
   "metadata": {},
   "source": [
    "# Get API key from user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d593a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI API Key········\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = getpass.getpass(prompt = \"OPENAI API Key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9c86a",
   "metadata": {},
   "source": [
    "# Define prompt options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1289cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sponsor = [[\"NSF\",\"2-page\", \"Data Management Plan\"],\n",
    "           [\"NIH\",\"2-page\", \"Data Sharing Plan\"],\n",
    "           [\"IMLS\",\"2-page\", \"Digital Product Plan\"]]\n",
    "\n",
    "PI = [\"PI-1\", \"PI-2\", \"PI-3\"]\n",
    "DataManager = [\"DM-1\", \"DM-2\", \"DM-3\"]\n",
    "\n",
    "SubjectAreas = [\"Human Subjects Research\", \"Environmental Analysis\", \"Algorithm Development\"]\n",
    "\n",
    "DataTypes = [\n",
    "    [\"Survey data\", \"MB\", \"Spreadsheet\", \"CSV\", \"ICPSR\", \"DDI\", \"Creative Commons\", [\"CC0\", \"CC BY 4.0\", \"CC BY SA 4.0\"]],\n",
    "    [\"GIS data\", \"GB\", \"Shapefiles\", \"GML\", \"Dryad\", \"DataCite and README\", \"Creative Commons\", [\"CC0\", \"CC BY 4.0\", \"CC BY SA 4.0\"]],\n",
    "    [\"Instrument derived data\", \"GB\", \"CSV\", \"CSV\", \"Dryad\", \"DataCite and README\", \"Creative Commons\", [\"CC0\", \"CC BY 4.0\", \"CC BY SA 4.0\"]],\n",
    "    [\"Software code\", \"MB\", random.choice([\"Matlab\",\"Python\",\"R\",\"Fortran\"]) + \"source code\", \"source code\",\"Zenodo\", \"DataCite and README\", \"Open Source\", [\"Apache-2.0\", \"GPL-3.0-only\", \"BSD-3-Clause\"]]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac9306",
   "metadata": {},
   "source": [
    "# Define prompt generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6fdce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptGen():\n",
    "    sponsorPrompt = random.choice(Sponsor)\n",
    "    piPrompt = random.choice(PI)\n",
    "    dmPrompt = random.choice(DataManager)\n",
    "    saPrompt = random.choice(SubjectAreas)\n",
    "    dtPrompt = random.choice(DataTypes)\n",
    "    dtVolPrompt = random.randrange(5,100)\n",
    "    dtLicPrompt = random.choice(dtPrompt[7])\n",
    "\n",
    "    promptText = (\"Write a \" + sponsorPrompt[1] + \" \" + sponsorPrompt[0] + \" \" + sponsorPrompt[2]\n",
    "          + \" for a research project led by \" + piPrompt + \" with data management led by \" + dmPrompt\n",
    "          + \"; in the subject area of \" + saPrompt\n",
    "          + \"; for which \" + str(dtVolPrompt) + dtPrompt[1] + \" of \" + dtPrompt[0] + \" will be generated for use during the project, resulting in \" + str(int(round(.8*dtVolPrompt,0))) + dtPrompt[1] + \" of \" + dtPrompt[3] + \" files that will be shared and preserved in the \" + dtPrompt[4] + \" repository\"\n",
    "          + \" and documented using the \" + dtPrompt[5] + \" standard(s)\"\n",
    "          + \"; shared under the terms of the \" + dtLicPrompt + \" \" + dtPrompt[6] + \" license\"\n",
    "          + \"; and preserved using UNM's LibNova Labdrive system for long-term preservation in addition to any additional preservation provided by the target repository\" \n",
    "         )\n",
    "    prompt = [{\"role\": \"user\", \"content\": promptText}]\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"You are a helpful assistant\"},\n",
    "        {\"role\":\"user\", \"content\":\"Write a \" + sponsorPrompt[1] + \" \" + sponsorPrompt[0] + \" \" + sponsorPrompt[2] + \" for a research project led by \" + piPrompt + \" with data management led by \" + dmPrompt},\n",
    "        {\"role\":\"user\", \"content\":\"The subject area of the data management plan is \" + saPrompt},\n",
    "        {\"role\":\"user\", \"content\":\"The project will generate \" + str(dtVolPrompt) + dtPrompt[1] + \" of \" + dtPrompt[0] + \" for use during the project, resulting in \" + str(int(round(.8*dtVolPrompt,0))) + dtPrompt[1] + \" of \" + dtPrompt[3] + \" files that will be shared and preserved in the \" + dtPrompt[4] + \" repository\"},\n",
    "        {\"role\":\"user\", \"content\":\"The data generated by the project will be documented using the \" + dtPrompt[5] + \" standard(s)\"},\n",
    "        {\"role\":\"user\", \"content\":\"The generated materials will be shared under the terms of the \" + dtLicPrompt + \" \" + dtPrompt[6] + \" license\"},\n",
    "        {\"role\":\"user\", \"content\":\"The generated materials will be preserved using UNM's LibNova Labdrive system for long-term preservation in addition to any additional preservation provided by the target repository\"}\n",
    "    ]\n",
    "\n",
    "    return {\"prompt\":prompt, \"messages\":messages}\n",
    "\n",
    "def promptDialog():\n",
    "    sponsorPrompt = random.choice(Sponsor)\n",
    "    piPrompt = random.choice(PI)\n",
    "    dmPrompt = random.choice(DataManager)\n",
    "    saPrompt = random.choice(SubjectAreas)\n",
    "    dtPrompt = random.choice(DataTypes)\n",
    "    dtVolPrompt = random.randrange(5,100)\n",
    "    dtLicPrompt = random.choice(dtPrompt[7])\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\":\"system\", \"content\":\"You are a helpful assistant\"},\n",
    "        {\"role\":\"user\", \"content\":\"Write a \" + sponsorPrompt[1] + \" \" + sponsorPrompt[0] + \" \" + sponsorPrompt[2] + \" for a research project led by \" + piPrompt + \" with data management led by \" + dmPrompt + \"; in the subject area of \" + saPrompt},\n",
    "        {\"role\":\"user\", \"content\":\"The subject area of the data management plan is \" + saPrompt},\n",
    "        {\"role\":\"user\", \"content\":\"The project will generate \" + str(dtVolPrompt) + dtPrompt[1] + \" of \" + dtPrompt[0] + \" for use during the project, resulting in \" + str(int(round(.8*dtVolPrompt,0))) + dtPrompt[1] + \" of \" + dtPrompt[3] + \" files that will be shared and preserved in the \" + dtPrompt[4] + \" repository\"},\n",
    "        {\"role\":\"user\", \"content\":\"The data generated by the project will be documented using the \" + dtPrompt[5] + \" standard(s)\"},\n",
    "        {\"role\":\"user\", \"content\":\"The generated materials will be shared under the terms of the \" + dtLicPrompt + \" \" + dtPrompt[6] + \" license\"},\n",
    "        {\"role\":\"user\", \"content\":\"The generated materials will be preserved using UNM's LibNova Labdrive system for long-term preservation in addition to any additional preservation provided by the target repository\"}\n",
    "    ]\n",
    "    return messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b846d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91064c8e",
   "metadata": {},
   "source": [
    "# Define prompt submission and return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a8a94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://platform.openai.com/docs/api-reference/completions/create for explanations of the submission parameters\n",
    "def dmpGen(promptText):\n",
    "    promptText = promptText\n",
    "    response = openai.ChatCompletion.create(\n",
    "      max_tokens=2048,\n",
    "      top_p=.25,\n",
    "      frequency_penalty=1.0,\n",
    "      presence_penalty=1.0,\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=promptText\n",
    "    )\n",
    "    return {\"prompt\":promptText, \"response\":response, \"dmp\":response['choices'][0]['message']['content']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756debe",
   "metadata": {},
   "source": [
    "# The resulting prompt and output was"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0809781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results for a single string prompt\n",
      "--------------------------------------\n",
      "\n",
      "The prompt was:\n",
      " [{'role': 'user', 'content': \"Write a 2-page NSF Data Management Plan for a research project led by PI-2 with data management led by DM-1; in the subject area of Environmental Analysis; for which 66GB of GIS data will be generated for use during the project, resulting in 53GB of GML files that will be shared and preserved in the Dryad repository and documented using the DataCite and README standard(s); shared under the terms of the CC0 Creative Commons license; and preserved using UNM's LibNova Labdrive system for long-term preservation in addition to any additional preservation provided by the target repository\"}]\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "The generated version-0 DMP was: \n",
      " .\n",
      "\n",
      "Introduction\n",
      "\n",
      "This Data Management Plan (DMP) outlines the data management practices for a research project led by PI-2 in the subject area of Environmental Analysis. The project aims to generate 66GB of GIS data, resulting in 53GB of GML files that will be shared and preserved in the Dryad repository. DM-1 will lead the data management efforts for this project.\n",
      "\n",
      "Data Collection\n",
      "\n",
      "The research team will collect GIS data using various sources such as satellite imagery, field surveys, and existing datasets. The collected data will be processed and analyzed using ArcGIS software to create maps and other visualizations.\n",
      "\n",
      "Data Sharing\n",
      "\n",
      "All generated GML files from this project will be shared with the scientific community through Dryad repository under CC0 Creative Commons license terms. This license allows anyone to use, distribute or modify these files without any restrictions or limitations.\n",
      "\n",
      "Data Preservation\n",
      "\n",
      "To ensure long-term preservation of all generated GML files beyond what is provided by Dryad repository, we plan to store them on UNM's LibNova Labdrive system. This system provides secure storage with backup facilities that can guarantee long-term preservation even if there are hardware failures or disasters.\n",
      "\n",
      "Metadata Documentation\n",
      "\n",
      "We plan to document all metadata related to our dataset following DataCite standards which include information about authors, title, publisher name(s), publication year(s), version number(s), DOI identifier(s), etc., so that others can easily find and reuse our dataset.\n",
      "\n",
      "README File Creation\n",
      "\n",
      "A README file containing detailed information about how we collected our GIS data including methods used during processing/analysis stages along with any relevant caveats or limitations associated with each stage would also be created alongside our dataset documentation according to standard guidelines set forth by repositories like Zenodo.org among others; this file would help users understand how they could best utilize our dataset while avoiding potential pitfalls due lack clarity around its creation process(es).\n",
      "\n",
      "Security Measures \n",
      "\n",
      "To protect sensitive information contained within some of our GIS data, we will ensure that all files are encrypted and password-protected before being uploaded to any repository. We will also limit access to these files only to authorized personnel who have signed confidentiality agreements.\n",
      "\n",
      "Data Reuse\n",
      "\n",
      "We encourage other researchers in the field of Environmental Analysis to reuse our dataset for their own research purposes. To facilitate this, we plan on providing detailed documentation about how the data was collected and processed so that others can easily understand its context and limitations.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "In conclusion, this DMP outlines the data management practices for a research project led by PI-2 with DM-1 leading the data management efforts. The project aims to generate 66GB of GIS data resulting in 53GB of GML files that will be shared and preserved in Dryad repository under CC0 Creative Commons license terms while also being stored on UNM's LibNova Labdrive system for long-term preservation beyond what is provided by Dryad repository. Metadata documentation following DataCite standards along with README file creation would help users better understand how they could best utilize our dataset while avoiding potential pitfalls due lack clarity around its creation process(es).\n",
      "\n",
      "==========================================================\n",
      "The results for a multi-message prompt\n",
      "--------------------------------------\n",
      "\n",
      "The prompt was:\n",
      " [{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'Write a 2-page NSF Data Management Plan for a research project led by PI-2 with data management led by DM-1; in the subject area of Environmental Analysis'}, {'role': 'user', 'content': 'The subject area of the data management plan is Environmental Analysis'}, {'role': 'user', 'content': 'The project will generate 66GB of GIS data for use during the project, resulting in 53GB of GML files that will be shared and preserved in the Dryad repository'}, {'role': 'user', 'content': 'The data generated by the project will be documented using the DataCite and README standard(s)'}, {'role': 'user', 'content': 'The generated materials will be shared under the terms of the CC0 Creative Commons license'}, {'role': 'user', 'content': \"The generated materials will be preserved using UNM's LibNova Labdrive system for long-term preservation in addition to any additional preservation provided by the target repository\"}]\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "The generated version-0 DMP was: \n",
      " NSF Data Management Plan\n",
      "\n",
      "Project Title: Environmental Analysis of [insert project title]\n",
      "\n",
      "Principal Investigator (PI): PI-2\n",
      "\n",
      "Data Management Lead: DM-1\n",
      "\n",
      "Introduction:\n",
      "\n",
      "The proposed research project aims to conduct an environmental analysis of [insert project details]. The study will generate approximately 66GB of GIS data, which includes 53GB of GML files. This data is essential for the success and reproducibility of the research outcomes. Therefore, this NSF Data Management Plan outlines how we plan to manage, document, share and preserve the generated data.\n",
      "\n",
      "Data Management Plan:\n",
      "\n",
      "1. Data Types and Formats:\n",
      "The primary data types that will be generated during this study include spatial datasets in GML format, metadata files in XML format, and documentation files in PDF format. These formats are widely used within the field of environmental analysis and are compatible with most Geographic Information System (GIS) software packages.\n",
      "\n",
      "2. Documentation:\n",
      "To ensure proper documentation throughout the lifecycle of our research project's data management process, we will use both DataCite metadata standards as well as README file standards for all datasets created or modified during this study.\n",
      "\n",
      "3. Storage:\n",
      "All generated materials will be stored on a secure server at UNM's LibNova Labdrive system for long-term preservation purposes in addition to any additional preservation provided by target repositories such as Dryad repository.\n",
      "\n",
      "4. Sharing:\n",
      "We plan to make all non-sensitive datasets available through public access repositories such as Dryad repository under CC0 Creative Commons license terms after publication or upon request from other researchers interested in using our dataset(s). We believe that sharing these resources can help advance scientific knowledge while also promoting transparency within our field.\n",
      "\n",
      "5. Preservation:\n",
      "Our team recognizes that preserving digital information is critical for future generations' ability to reproduce results accurately; therefore, we have taken steps towards ensuring long-term preservation by storing copies on multiple servers across different geographic locations with regular backups scheduled every six months.\n",
      "\n",
      "6. Data Management Roles and Responsibilities:\n",
      "The PI-2 will oversee the data management process, while DM-1 will be responsible for ensuring that all generated materials are appropriately documented, stored, shared and preserved according to this NSF Data Management Plan.\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "In conclusion, we believe that our proposed data management plan is comprehensive and meets the requirements set forth by the National Science Foundation (NSF). We have taken steps towards ensuring proper documentation of datasets using standard metadata formats such as DataCite and README files. Additionally, we plan to store copies on multiple servers across different geographic locations with regular backups scheduled every six months. Finally, we aim to share non-sensitive datasets through public access repositories under CC0 Creative Commons license terms after publication or upon request from other researchers interested in using our dataset(s).\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "prompts = promptGen() \n",
    "singlePrompt = dmpGen(prompts['prompt'])\n",
    "multiPrompt = dmpGen(prompts['messages'])\n",
    "\n",
    "print(\"The results for a single string prompt\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\nThe prompt was:\\n\" , singlePrompt[\"prompt\"])\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\nThe generated version-0 DMP was: \\n\", singlePrompt[\"dmp\"])\n",
    "print(\"\\n==========================================================\")\n",
    "print(\"The results for a multi-message prompt\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"\\nThe prompt was:\\n\" , multiPrompt[\"prompt\"])\n",
    "print(\"++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "print(\"\\nThe generated version-0 DMP was: \\n\", multiPrompt[\"dmp\"])\n",
    "print(\"============================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b6786",
   "metadata": {},
   "source": [
    "# Generate multiple request-response sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00c7b6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1 out of 40\n",
      "Request: 2 out of 40\n",
      "Request: 3 out of 40\n",
      "Request: 4 out of 40\n",
      "Request: 5 out of 40\n",
      "Request: 6 out of 40\n",
      "Request: 7 out of 40\n",
      "Request: 8 out of 40\n",
      "Request: 9 out of 40\n",
      "Request: 10 out of 40\n",
      "Request: 11 out of 40\n",
      "Request: 12 out of 40\n",
      "Request: 13 out of 40\n",
      "Request: 14 out of 40\n",
      "Request: 15 out of 40\n",
      "Request: 16 out of 40\n",
      "Request: 17 out of 40\n",
      "Request: 18 out of 40\n",
      "Request: 19 out of 40\n",
      "Request: 20 out of 40\n",
      "Request: 21 out of 40\n",
      "Request: 22 out of 40\n",
      "Request: 23 out of 40\n",
      "Request: 24 out of 40\n",
      "Request: 25 out of 40\n",
      "Request: 26 out of 40\n",
      "Request: 27 out of 40\n",
      "Request: 28 out of 40\n",
      "Request: 29 out of 40\n",
      "Request: 30 out of 40\n",
      "Request: 31 out of 40\n",
      "Request: 32 out of 40\n",
      "Request: 33 out of 40\n",
      "Request: 34 out of 40\n",
      "Request: 35 out of 40\n",
      "Request: 36 out of 40\n",
      "Request: 37 out of 40\n",
      "Request: 38 out of 40\n",
      "Request: 39 out of 40\n",
      "Request: 40 out of 40\n"
     ]
    }
   ],
   "source": [
    "filename = \"requestResponseSets_\" + str(datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%S.%fZ\")) + \".txt\"\n",
    "with open(filename, 'w') as f:\n",
    "    numberOfPrompts = 40\n",
    "    requestNumber = 0\n",
    "    while requestNumber < numberOfPrompts:\n",
    "        requestNumber = requestNumber + 1\n",
    "        print(\"Request: \" + str(requestNumber) + \" out of \" + str(numberOfPrompts))\n",
    "        prompts = promptGen() \n",
    "        singlePrompt = dmpGen(prompts['prompt'])\n",
    "        time.sleep(60) # wait to avoid generating ChatGPT rate limits\n",
    "        multiPrompt = dmpGen(prompts['messages'])\n",
    "        time.sleep(60) # wait to avoid generating ChatGPT rate limits\n",
    "        f.write(\"======================================\\n\")\n",
    "        f.write(\"== Prompt set: \" + str(requestNumber) + \"\\n\" )\n",
    "        f.write(\"======================================\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"The results for a single string prompt\\n\")\n",
    "        f.write(\"--------------------------------------\\n\")\n",
    "        f.write(\"\\nThe prompt was:\\n\" + str(singlePrompt[\"prompt\"]) + \"\\n\")\n",
    "        f.write(\"++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        f.write(\"\\nThe generated version-0 DMP was: \\n\" + singlePrompt[\"dmp\"] + \"\\n\")\n",
    "        f.write(\"\\n==========================================================\\n\")\n",
    "        f.write(\"The results for a multi-message prompt\\n\")\n",
    "        f.write(\"--------------------------------------\")\n",
    "        f.write(\"\\nThe prompt was:\\n\" + str(multiPrompt[\"prompt\"]) + \"\\n\")\n",
    "        f.write(\"++++++++++++++++++++++++++++++++++++++++++++\\n\")\n",
    "        f.write(\"\\nThe generated version-0 DMP was: \\n\" + multiPrompt[\"dmp\"] + \"\\n\")\n",
    "        f.write(\"============================================================\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96439532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
